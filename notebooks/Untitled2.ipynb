{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:\\GitRepos\\onhm-fetcher-parser\\notebooks\n",
      "..\\Data_v1_1\n",
      "            GM_LAYER         LAYER            GM_TYPE  OBJECTID  hru_segmen  \\\n",
      "0       NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type         1        1551   \n",
      "1       NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type         2        1551   \n",
      "2       NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type         3        1547   \n",
      "3       NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type         3        1547   \n",
      "4       NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type         4        1555   \n",
      "...              ...           ...                ...       ...         ...   \n",
      "140767  NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type    114951         294   \n",
      "140768  NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type    114952         285   \n",
      "140769  NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type    114953         226   \n",
      "140770  NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type    114954         294   \n",
      "140771  NHM\\nhru_v11  NHM\\nhru_v11  Unknown Area Type    114955         115   \n",
      "\n",
      "       region  hru_id_nat  hru_id_loc  nhm_id          POI_ID  hru_segme1  \\\n",
      "0          12       74427        1172   74427       4133491.0       39315   \n",
      "1          12       74450        1195   74450       4133491.0       39315   \n",
      "2          12       74490        1235   74490       4133273.0       39311   \n",
      "3          12       74490        1235   74490       4133273.0       39311   \n",
      "4          12       74496        1241   74496       4133611.0       39319   \n",
      "...       ...         ...         ...     ...             ...         ...   \n",
      "140767     01           0        1225  111175  10000900012033       57042   \n",
      "140768     01           0        1226  111176  10000900009494       57033   \n",
      "140769     01           0        1227  111177  10000900003964       56974   \n",
      "140770     01           0        1228  111178  10000900012033       57042   \n",
      "140771     01           0        1229  111179  10000900001807       56863   \n",
      "\n",
      "       region_src   Shape_Leng Shape_Area  GFv11_id  hru_segme2  \\\n",
      "0              12   17746.3250  2010572.0     74427       39315   \n",
      "1              12   40039.9540   32998570     74450       39315   \n",
      "2              12   80333.0610  118674844     74490       39311   \n",
      "3              12   80333.0610  118674844     74490       39311   \n",
      "4              12    3949.9514  295118.91     74496       39319   \n",
      "...           ...          ...        ...       ...         ...   \n",
      "140767       0108   20526.1740  7750669.5     45611       23343   \n",
      "140768       0108   25982.0130  9016503.8     45612       23334   \n",
      "140769       0108   57553.4230   66296531     45613       23275   \n",
      "140770       0108   26693.6210   15726630     45614       23343   \n",
      "140771       0108  117795.1000  300732842     45615        1150   \n",
      "\n",
      "                                                 geometry  \n",
      "0       POLYGON ((-96.59366 31.80448, -96.59366 31.804...  \n",
      "1       POLYGON ((-96.68742 31.86463, -96.68710 31.864...  \n",
      "2       POLYGON ((-96.80789 31.87379, -96.80790 31.874...  \n",
      "3       POLYGON ((-96.80789 31.87379, -96.80789 31.873...  \n",
      "4       POLYGON ((-96.78781 31.93710, -96.78781 31.936...  \n",
      "...                                                   ...  \n",
      "140767  POLYGON ((-71.16736 45.24702, -71.16292 45.243...  \n",
      "140768  POLYGON ((-71.19630 45.25387, -71.19633 45.253...  \n",
      "140769  POLYGON ((-71.11149 45.23954, -71.11152 45.239...  \n",
      "140770  POLYGON ((-71.16173 45.25005, -71.16176 45.249...  \n",
      "140771  POLYGON ((-71.28363 45.30249, -71.28367 45.302...  \n",
      "\n",
      "[140772 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "# folder = Path(r'../Data') # assumes working directory is onhm-fetcher-parser\n",
    "folder = Path(r'../Data_v1_1') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "# shapefiles = folder.glob(\"*_0[1-2].shp\")\n",
    "shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var=lat&var=lon&var=prcp&var=srad&var=swe&var=tmax&var=tmin&var=vp&north=54&west=-126&east=-65&south=23&disableProjSubset=on&horizStride=1&time_start=2018-12-31T12%3A00%3A00Z&time_end=2018-12-31T12%3A00%3A00Z&timeStride=1&accept=netcdf\n",
      "Gridmet data retrieved!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "prcpurl = 'https://thredds.daac.ornl.gov/thredds/ncss/daymet-v3-agg/na.ncml'\n",
    "prcppayload = {\n",
    "#     'var': 'lat&var=lon&var=tmax',\n",
    "    'var': 'lat&var=lon&var=prcp&var=srad&var=swe&var=tmax&var=tmin&var=vp',\n",
    "    'north': '54',\n",
    "    'west': '-126',\n",
    "    'east': '-65',\n",
    "    'south': '23',\n",
    "    'disableProjSubset': 'on',\n",
    "    'horizStride': '1',\n",
    "    'time_start': '2018-12-31T12:00:00Z',\n",
    "    'time_end': '2018-12-31T12:00:00Z',\n",
    "    'timeStride': '1',\n",
    "    'accept': 'netcdf'}    \n",
    "try:\n",
    "    s = requests.Session()\n",
    "    #https://github.com/psf/requests/issues/1454\n",
    "    qry = urlencode(prcppayload).replace('%26','&')\n",
    "    qry = qry.replace('%3D', '=')\n",
    "    print(qry)\n",
    "    tmaxfile = requests.get(prcpurl, params=qry)\n",
    "    tmaxfile.raise_for_status()\n",
    "except HTTPError as http_err:\n",
    "    print(f'HTTP error occured: {http_err}')\n",
    "except Exception as err:\n",
    "    print(f'Other error occured: {err}')\n",
    "else:\n",
    "    print('Gridmet data retrieved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('tmax_test2.nc', 'wb') as fh:\n",
    "    fh.write(tmaxfile.content)\n",
    "fh.close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmax_test2.nc\n",
      "<xarray.Dataset>\n",
      "Dimensions:                  (time: 1, x: 5904, y: 3377)\n",
      "Coordinates:\n",
      "  * y                        (y) float32 1687.0 1686.0 ... -1688.0 -1689.0\n",
      "  * x                        (x) float32 -2650.25 -2649.25 ... 3251.75 3252.75\n",
      "  * time                     (time) datetime64[ns] 2018-12-31\n",
      "Data variables:\n",
      "    lat                      (y, x) float32 ...\n",
      "    lambert_conformal_conic  int16 ...\n",
      "    lon                      (y, x) float32 ...\n",
      "    prcp                     (time, y, x) float32 ...\n",
      "    srad                     (time, y, x) float32 ...\n",
      "    swe                      (time, y, x) float32 ...\n",
      "    tmax                     (time, y, x) float32 ...\n",
      "    tmin                     (time, y, x) float32 ...\n",
      "    vp                       (time, y, x) float32 ...\n",
      "Attributes:\n",
      "    _NCProperties:       version=1|netcdflibversion=4.4.1|hdf5libversion=1.8.17\n",
      "    start_year:          1980\n",
      "    source:              Daymet Software Version 3.0\n",
      "    Version_software:    Daymet Software Version 3.0\n",
      "    Version_data:        Daymet Data Version 3.0\n",
      "    Conventions:         CF-1.6\n",
      "    citation:            Please see http://daymet.ornl.gov/ for current Dayme...\n",
      "    references:          Please see http://daymet.ornl.gov/ for current infor...\n",
      "    title:               Daymet: Daily Surface Weather Data on a 1-km Grid fo...\n",
      "    institution:         Oak Ridge National Laboratory Distributed Active Arc...\n",
      "    end_year:            2018\n",
      "    History:             Translated to CF-1.0 Conventions by Netcdf-Java CDM ...\n",
      "    geospatial_lat_min:  21.185654454541883\n",
      "    geospatial_lat_max:  58.14529038788518\n",
      "    geospatial_lon_min:  -141.7181355648655\n",
      "    geospatial_lon_max:  -50.72062839852924\n",
      "\n",
      " The meta data is: \n",
      " {'_NCProperties': 'version=1|netcdflibversion=4.4.1|hdf5libversion=1.8.17', 'start_year': 1980, 'source': 'Daymet Software Version 3.0', 'Version_software': 'Daymet Software Version 3.0', 'Version_data': 'Daymet Data Version 3.0', 'Conventions': 'CF-1.6', 'citation': 'Please see http://daymet.ornl.gov/ for current Daymet data citation information', 'references': 'Please see http://daymet.ornl.gov/ for current information on Daymet references', 'title': 'Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 3 (Continental North America)', 'institution': 'Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC)', 'end_year': 2018, 'History': 'Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\\nOriginal Dataset = file:/daymet/V3/CFMosaicAgg/na.ncml; Translation Date = 2019-12-27T16:44:37.212Z', 'geospatial_lat_min': 21.185654454541883, 'geospatial_lat_max': 58.14529038788518, 'geospatial_lon_min': -141.7181355648655, 'geospatial_lon_max': -50.72062839852924}\n",
      "\n",
      " The crs meta data is \n",
      " {'grid_mapping_name': 'lambert_conformal_conic', 'longitude_of_central_meridian': -100.0, 'latitude_of_projection_origin': 42.5, 'false_easting': 0.0, 'false_northing': 0.0, 'standard_parallel': array([25., 60.]), 'semi_major_axis': 6378137.0, 'inverse_flattening': 298.257223563, 'longitude_of_prime_meridian': 0.0, '_CoordinateTransformType': 'Projection', '_CoordinateAxisTypes': 'GeoX GeoY'}\n",
      "<xarray.DataArray 'tmax' (time: 1, y: 3377, x: 5904)>\n",
      "[19937808 values with dtype=float32]\n",
      "Coordinates:\n",
      "  * y        (y) float32 1687.0 1686.0 1685.0 1684.0 ... -1687.0 -1688.0 -1689.0\n",
      "  * x        (x) float32 -2650.25 -2649.25 -2648.25 ... 3250.75 3251.75 3252.75\n",
      "  * time     (time) datetime64[ns] 2018-12-31\n",
      "Attributes:\n",
      "    long_name:     daily maximum temperature\n",
      "    units:         degrees C\n",
      "    grid_mapping:  lambert_conformal_conic\n",
      "    cell_methods:  area: mean time: maximum\n",
      "    _ChunkSizes:   [   1 1000 1000]\n",
      "\n",
      " Data attributes, sizes, and coords \n",
      "\n",
      "\n",
      " Data attributes are: \n",
      " {'long_name': 'daily maximum temperature', 'units': 'degrees C', 'grid_mapping': 'lambert_conformal_conic', 'cell_methods': 'area: mean time: maximum', '_ChunkSizes': array([   1, 1000, 1000])}\n",
      "\n",
      " Data sizes are: \n",
      " Frozen({'time': 1, 'y': 3377, 'x': 5904})\n",
      "\n",
      " Data coords are: \n",
      " Coordinates:\n",
      "  * y        (y) float32 1687.0 1686.0 1685.0 1684.0 ... -1687.0 -1688.0 -1689.0\n",
      "  * x        (x) float32 -2650.25 -2649.25 -2648.25 ... 3250.75 3251.75 3252.75\n",
      "  * time     (time) datetime64[ns] 2018-12-31\n",
      "\n",
      " Lat coords are: \n",
      " {'units': 'degrees_north', 'long_name': 'latitude coordinate', 'standard_name': 'latitude', '_ChunkSizes': array([1010,  977]), '_CoordinateAxisType': 'Lat', 'grid_mapping': 'lambert_conformal_conic'}\n",
      "xarray.core.utils.Frozen\n",
      "1\n",
      "1 5904 3377\n"
     ]
    }
   ],
   "source": [
    "#=========================================================\n",
    "#            MACAV2METDATA FILE PARAMETERS\n",
    "#=========================================================\n",
    "# dirPath='https://thredds.daac.ornl.gov/thredds/ncss/ornldaac/1328/2018/daymet_v3_prcp_2018_na.nc4?var=lat&var=lon&var=prcp&north=52.880049298000074+&west=-124.72462483099997+&east=-66.94953853699997+&south=24.839424370000074&disableLLSubset=on&disableProjSubset=on&horizStride=1&time_start=2018-12-31T00:00:00Z&time_end=2018-12-31T00:00:00Z&timeStride=1&accept=netcdf'\n",
    "# fileName='/thredds/dodsC/MET/tmmx/tmmx_2019.nc'\n",
    "dirPath = 'tmax_test2.nc'\n",
    "# dirPath = 'daymet_v3_tmax_2018_na.nc4.nc'\n",
    "#--------------------------------------------------------\n",
    "#   FORM FILENAME AND GET HANDLE TO FILE AND DATA\n",
    "#--------------------------------------------------------\n",
    "fullfilename= dirPath\n",
    "print(fullfilename)\n",
    "\n",
    "ds = xr.open_dataset(fullfilename)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "print('\\n The meta data is: \\n', ds.attrs)\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['time']\n",
    "datahandle=ds['tmax']\n",
    "dhlat = ds['lat']\n",
    "dhlon = ds['lon']\n",
    "crshandle=ds['lambert_conformal_conic']\n",
    "print('\\n The crs meta data is \\n', crshandle.attrs)\n",
    "print(datahandle)\n",
    "# crstransform = crshandle.attrs['GeoTransform']\n",
    "# print(crstransform)\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "# lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "# latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "print('\\n Data attributes are: \\n',datahandle.attrs)\n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "print('\\n Lat coords are: \\n', dhlat.attrs)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['time'])\n",
    "dayshape = ts['time']\n",
    "Lonshape = ts['x']\n",
    "Latshape = ts['y']\n",
    "#dayshape,lonshape,latshape = datahandle.values.shape\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n",
    "# datahandle.values[dayshape-1,:,:].shape\n",
    "\n",
    "# print(lathandle.values.shape)\n",
    "# print(type(lathandle.values))\n",
    "# print(datahandle.dtype)\n",
    "# print(np.isfortran(datahandle.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   grid_ids  nhm_id  hru_id_nat         w\n",
      "0    585567   74427       74427  0.022644\n",
      "1    585568   74427       74427  0.729424\n",
      "2    585566   74427       74427  0.247932\n",
      "3    585567   74450       74450  0.011813\n",
      "4    585565   74450       74450  0.077199\n",
      "[-6.5 -6.5 -6.5 ...  nan  nan  nan]\n",
      "140772 113310\n",
      "<class 'numpy.float64'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmcd\\anaconda3\\envs\\ofp_env_upd\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "113594",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d5483aa07e98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mtd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mweight_id_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_hru_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nhm_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;31m#     print(weight_id_rows['grid_ids'].values.astype(int))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ofp_env_upd\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mget_group\u001b[1;34m(self, name, obj)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[0minds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 113594"
     ]
    }
   ],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=0.0\n",
    "\n",
    "#open weight data\n",
    "#wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "#wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "#wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "wght_UofI = pd.read_csv('../pkg/tmp_weights2.csv')\n",
    "# print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), \n",
    "#       len(wght_df_500['hru_id_nat'].unique()), len(wght_UofI['hru_id_nat'].unique()))\n",
    "print(wght_UofI.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# ndata=np.nan_to_num(data)\n",
    "print(ndata[1000:])\n",
    "# def w_mean(data)\n",
    "unique_hru_ids = wght_UofI.groupby('nhm_id')\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "\n",
    "def get_wval(grp, ndata):\n",
    "    ttmax = twght = 0.0\n",
    "    for index, row in grp.iterrows():\n",
    "        ttmax += row['w']*ndata[np.int(row['grid_ids'])]\n",
    "        twght += row['w']\n",
    "    return ttmax/twght\n",
    "def np_get_wval(grp, ndata):\n",
    "    return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "def np_get_wval2(grp, ndata):\n",
    "    mdata = np.ma.masked_array(ndata[grp['grid_ids'].values.astype(int)], np.isnan(ndata[grp['grid_ids'].values.astype(int)]))\n",
    "    return np.ma.average(mdata, weights=grp['w'])\n",
    "#     return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "    \n",
    "# unique_hru_ids.get_group(gdf['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})    \n",
    "td = np.zeros(len(gdf.index))\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = unique_hru_ids.get_group(row['nhm_id'])\n",
    "#     print(weight_id_rows['grid_ids'].values.astype(int))\n",
    "#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\n",
    "#     gdf.loc[gdf.index[index],'tmax'] = np_get_wval(weight_id_rows, ndata)-273.5\n",
    "    tmp = np_get_wval2(weight_id_rows, ndata)\n",
    "    if index == 1:\n",
    "        print(type(tmp))\n",
    "    td[index] = np_get_wval2(weight_id_rows, ndata)\n",
    "#     if td[index] < 0.0:\n",
    "#         print(ndata[weight_id_rows['grid_ids'].values.astype(int)], weight_id_rows['w'])\n",
    "#     print(index, td[index])\n",
    "#     if row['hru_id_nat'] == 829:\n",
    "#         print(\"in test\")\n",
    "#         for i2, el in weight_id_rows.iterrows():\n",
    "#             print(el['w'], ndata[el['grid_ids'].astype(int)])\n",
    "#         print(np.average(ndata[weight_id_rows['grid_ids'].values.astype(int)], weights=weight_id_rows['w'])-273.5)\n",
    "#     print(index, row['hru_id_nat'], np_get_wval(weight_id_rows, ndata)-273.5)\n",
    "#     gdf.loc[gdf.index[index], 'tmax'] =\n",
    "# #     print(get_wval(weight_id_rows, ndata)-273.5)\n",
    "# #     row.loc['tmax']=get_wval(weight_id_rows, ndata)-273.5\n",
    "# #     gdf.loc[gdf.index[index], 'tmax'] = get_wval(weight_id_rows, ndata)-273.5\n",
    "# print(len(td))\n",
    "# gdf['tmax'] = gpd.GeoSeries([np.transpose(td)], index=gdf.index)\n",
    "gdf['tmax'] = td.tolist()\n",
    "gdf['tmax'].fillna(0.0)\n",
    "# print(td.tolist())\n",
    "print('min/max', gdf['tmax'].min(), gdf['tmax'].max())\n",
    "# print(gdf)\n",
    "# gdf.plot(figsize=(12,12), column = 'tmax',linewidth=0.25, edgecolor='white')    \n",
    "# print(gdf.groupby(tmax).min)\n",
    "f, ax = plt.subplots(2, figsize=(12,12))\n",
    "gdf.plot(ax=ax[0], column = 'tmax',linewidth=0., edgecolor='white', scheme='quantiles')\n",
    "ptmax = ds.air_temperature-273.5\n",
    "ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.5)\n",
    "ptmax_1.plot(ax=ax[1], levels=lvs, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
